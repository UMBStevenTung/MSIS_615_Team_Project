{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00361f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, time, re, sqlite3, matplotlib.pyplot as plt, numpy as npy\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.common.by import By\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_experimental_option(\"detach\",True)\n",
    "service=ChromeService(ChromeDriverManager().install()) # instead of pointing to a specific path -> just install the service to use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0538dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(service=service,options=options)\n",
    "\n",
    "sqliteconnection = sqlite3.connect('MSIS615GroupProjectDB')\n",
    "cursor = sqliteconnection.cursor()\n",
    "\n",
    "company_list = ['MSFT','AAPL','AMZN','GOOGL','META','TSLA','NFLX','NVDA','BABA','CRM','AMD','INTC'] # list of tickers, update as needed\n",
    "\n",
    "regexth = re.compile(r'<th class=.*?><span>(.*?)</span></th>',re.S|re.I) # regular expression for table headers.\n",
    "regextd = re.compile(r'<td class=.*?><span>(.*?)</span></td>',re.S|re.I) # regular expression to identify table data.\n",
    "table_data_pattern = re.compile(r'... \\d\\d, \\d\\d\\d\\d',re.S|re.I) # regular expression to help group data into lists.\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "def scroll_bot(SCROLL_PAUSE_TIME=0.5): # scrolling function, default time is 0.5s\n",
    "    last_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "        new_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "def group_list(data_list,table_data_pattern,company_name): # function to group data into lists, with a final product being a list of all the lists\n",
    "    result = [] # finalize grouping of data points\n",
    "    for el in data_list:\n",
    "        if table_data_pattern.match(el):\n",
    "            row = []\n",
    "            result.append(row)\n",
    "            row.append(company_name)\n",
    "        row.append(el)\n",
    "    mylist = [c for c in result if len(c)>2 and len(c)<9]\n",
    "    return mylist\n",
    "        \n",
    "for company_name in company_list:\n",
    "    driver.get(f'https://finance.yahoo.com/quote/{company_name}/history?period1=1524182400&period2=1681948800&interval=1d&filter=history&frequency=1d&includeAdjustedClose=true')\n",
    "    time.sleep(3)\n",
    "    \n",
    "    scroll_bot()\n",
    "    \n",
    "    get_table = driver.find_element(By.XPATH,'//table[@data-test=\"historical-prices\"]') # Pull the specific table data -> reduce size for processing\n",
    "    table_source = get_table.get_attribute('innerHTML') # process web element into html\n",
    "    \n",
    "    data_list = regextd.findall(table_source)\n",
    "    temp_list = group_list(data_list,table_data_pattern,company_name) \n",
    "    temp_df = pd.DataFrame(temp_list) # create a temp dataframe to concat to existing dataframe\n",
    "    df = pd.concat([df,temp_df])\n",
    "\n",
    "header_list=['Company'] + regexth.findall(table_source) # create a list that includes all headers within the table and 'company' column for differentiating companies.\n",
    "df.columns = header_list\n",
    "df['Date'] = pd.to_datetime(df['Date']).dt.date # convert dates to proper data type.\n",
    "\n",
    "driver.close()\n",
    "\n",
    "df.to_sql(name='Tech_Stock_History',con=sqliteconnection,if_exists='replace',index=False) # Create table, if exists, replaces with same name table - uses dataframe data - https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_sql.html\n",
    "query_data = pd.read_sql('Select * From Tech_Stock_History', sqliteconnection) # Create second dataframe for querying/not accidentally overwrite the first dataframe\n",
    "\n",
    "display(query_data) # This is for viewing the data that was inserted to sqlite3 db to confirm it was successful\n",
    "# print(query_data) # display is a function unique to jupyter notebook and jupyter extensions.\n",
    "\n",
    "sqliteconnection.commit()\n",
    "sqliteconnection.close() # CLOSE CONNECTION AS NOT NEEDED ANYMORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806f4999",
   "metadata": {},
   "outputs": [],
   "source": [
    "faang = ['META', 'AAPL', 'AMZN', 'NFLX', 'GOOGL']\n",
    "query_data['Date'] = pd.to_datetime(query_data['Date'])\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [12,12] # Resize plot to make it more easier to see.\n",
    "\n",
    "# Group data by Company and Date, and calculate average Adj Close for each group\n",
    "grouped_data = query_data.groupby(['Company','Date']).mean()['Adj Close**'].reset_index()\n",
    "\n",
    "# Pivot the table to have Company as columns and Date as index\n",
    "pivot_data = grouped_data.pivot(index='Date',columns='Company',values='Adj Close**')\n",
    "\n",
    "# Plot the closing price for each company over time\n",
    "pivot_data.plot()\n",
    "\n",
    "# Set up legend and graph.\n",
    "plt.legend()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Adj Close Price (in $USD)')\n",
    "plt.title('Performance Comparison of Tech Companies')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd69199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only data for FAANG companies\n",
    "faang_data = query_data[query_data['Company'].isin(faang)]\n",
    "\n",
    "# Convert Date column to datetime format\n",
    "#faang_data['Date'] = pd.to_datetime(faang_data['Date'])\n",
    "\n",
    "# Group data by Company and Date, and calculate average Adj Close for each group\n",
    "faang_data = faang_data.groupby(['Company', 'Date']).mean()['Adj Close**'].reset_index()\n",
    "\n",
    "# Pivot the table to have Company as columns and Date as index\n",
    "faang_data = faang_data.pivot(index='Date', columns='Company', values='Adj Close**')\n",
    "\n",
    "# Plot the closing price for each company over time\n",
    "faang_data.plot()\n",
    "\n",
    "# Calculate the average closing price over time\n",
    "average_faang_data = faang_data.mean(axis=1)\n",
    "\n",
    "# Plot the average closing price over time\n",
    "average_faang_data.plot(label='Industry Average')\n",
    "\n",
    "# Find the minimum and maximum dates in the data\n",
    "min_date = faang_data.index.min()\n",
    "max_date = faang_data.index.max()\n",
    "\n",
    "# Create a range of dates to use for the regression line\n",
    "reg_dates = pd.date_range(start=min_date, end=max_date, freq='D')\n",
    "reg_dates = reg_dates[reg_dates.isin(faang_data.index)]\n",
    "\n",
    "# Fit a linear regression line to the average closing price using the new dates\n",
    "X_reg = pd.DataFrame({'x': range(len(reg_dates))}, index=reg_dates)\n",
    "Y_reg = average_faang_data.values.reshape(-1, 1)\n",
    "reg = LinearRegression().fit(X_reg, Y_reg)\n",
    "y_pred = reg.predict(X_reg)\n",
    "plt.plot(X_reg.index, y_pred, label='Linear Regression')\n",
    "\n",
    "\n",
    "# Add legend and labels to the graph\n",
    "plt.legend()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Adj Close Price')\n",
    "plt.title('FAANG Company Stock Performance')\n",
    "\n",
    "# Show the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59752f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the average closing price over time\n",
    "average_faang_data.plot(label='Industry Average')\n",
    "plt.plot(X_reg.index, y_pred, label='Linear Regression')\n",
    "\n",
    "# plot formatting\n",
    "plt.legend()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Adj Close Price (in $USD)')\n",
    "plt.title('Industry Average Performance')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0344e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "faang_average = faang_data.mean(axis=1)\n",
    "msft_data = pivot_data['MSFT']\n",
    "tsla_data = pivot_data['TSLA']\n",
    "\n",
    "plt.plot(faang_average.index, faang_average, label='FAANG Average')\n",
    "plt.plot(msft_data.index, msft_data, label='Microsoft')\n",
    "plt.plot(tsla_data.index, tsla_data, label='Tesla')\n",
    "\n",
    "# plot formatting\n",
    "plt.legend()\n",
    "plt.title('Microsoft and Tesla Performance against FAANG Average')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Closing Price (in $USD)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2eb532",
   "metadata": {},
   "outputs": [],
   "source": [
    "faang_average = faang_data.mean(axis=1)\n",
    "baba_data = pivot_data['BABA']\n",
    "\n",
    "plt.plot(faang_average.index, faang_average, label='FAANG Average')\n",
    "plt.plot(baba_data.index, baba_data, label='Alibaba')\n",
    "\n",
    "# plot formatting\n",
    "plt.legend()\n",
    "plt.title('Alibaba Performance against FAANG Average')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Closing Price (in $USD)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdbae4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average closing price for each stock\n",
    "avg_data = faang_data.mean()\n",
    "#print(avg_data)\n",
    "# Sort the stocks based on the average closing price\n",
    "sorted_data = avg_data.sort_values(ascending=False)\n",
    "#print(sorted_data)\n",
    "# Get the top 3 performers\n",
    "top_performers = sorted_data[:3].index.tolist()\n",
    "\n",
    "# Plot a histogram of the closing prices for each stock\n",
    "colors = ['red', 'green', 'blue']\n",
    "for i, stock in enumerate(top_performers):\n",
    "    plt.hist(faang_data[stock], bins=50, alpha=0.5, color=colors[i], label=stock)\n",
    "\n",
    "# plot formatting\n",
    "plt.legend()\n",
    "plt.xlabel('Closing Price')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of 3 Best FAANG Performers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42991a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = faang_data['META'].resample('m').last()\n",
    "\n",
    "plt.scatter(meta_data.index, meta_data, label='Facebook')\n",
    "\n",
    "plt.plot(X_reg.index, y_pred, label='Linear Regression',c ='red')\n",
    "\n",
    "# Add legend and labels to the graph\n",
    "plt.legend()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Adj Close Price')\n",
    "plt.title('Facebook Stock Analysis')\n",
    "\n",
    "# Show the graph\n",
    "plt.show()\n",
    "\n",
    "\n",
    "Print(\"Hello World\")\n",
    "Print(\"1+1 = 3\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
